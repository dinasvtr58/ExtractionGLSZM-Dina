{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9b343c",
   "metadata": {},
   "source": [
    "# 1. Import File CSV (Hasil Ekstraksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadaee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"C:.../.../Datasets Training GLSZM.csv\") # import data training\n",
    "test = pd.read_csv(\"C:.../.../Datasets Testing GLSZM.csv\") # import data testing\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ac631",
   "metadata": {},
   "source": [
    "# 2. Pengambilan fitur dan class dari data training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44420bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Penggunaan iloc dalam pandas adalah untuk seleksi berbasis posisi (integer-location based indexing) \n",
    "yang memungkinkan pemilihan bagian tertentu dari DataFrame berdasarkan posisi baris dan kolom.\n",
    "\n",
    "Di sini, 0:,:-1 berarti kita memilih semua baris (0:) dan semua kolom \n",
    "kecuali kolom terakhir (:-1), karena kolom terakhir dianggap sebagai variabel class.\n",
    "(-1) berarti hanya kolom terakhir yaitu kolom class.\n",
    "\n",
    "'''\n",
    "# Pengambilan fitur dan class\n",
    "X_train = train.iloc[0:,:-1] # Fitur\n",
    "y_train = train.iloc[0:,-1] # Class (anechoic, heterogeneous, hypoechoic)\n",
    "# print(y_train)\n",
    "\n",
    "X_test = test.iloc[0:,:-1] # Features\n",
    "y_test = test.iloc[0:,-1] # Class Target\n",
    "# print(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c7cd3",
   "metadata": {},
   "source": [
    "# 3. Normalisasi data fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "StandardScaler adalah sebuah metode untuk normalisasi data dengan \n",
    "skala 0-1 \n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train) # menghitung mean dan standar deviasi\n",
    "X_train_scaled = sc.transform(X_train) # transform x_train menjadi data standar\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d564c1",
   "metadata": {},
   "source": [
    "# 4. Class/label diubah dalam bentuk numerik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276db78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LabelEncoder untuk mengubah label menjadi angka karena MLP memerlukan\n",
    "output bentuk numerik\n",
    "'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_preprocessed = le.transform(y_train)\n",
    "y_test_preprocessed = le.transform(y_test)\n",
    "\n",
    "print(y_train_preprocessed)\n",
    "print(y_test_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a8079",
   "metadata": {},
   "source": [
    "# 5. Klasifikasi dan confussion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae378460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train_classification(clf, train_features, train_labels, test_features, test_labels):\n",
    "    clf.fit(train_features, train_labels)\n",
    "    test_predict = clf.predict(test_features)\n",
    "    return test_labels, test_predict\n",
    "\n",
    "def evaluation(clf, test_labels, test_predict, filename):\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(test_labels, test_predict)\n",
    "    plt.figure(3)\n",
    "    fig = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "    fig.plot()\n",
    "    plt.savefig('C:.../.../' + filename + ' Confusion Matrix.png') #sesuaikan dengan path\n",
    "    \n",
    "    # Mendapatkan nilai TP, FP, FN, TN untuk setiap kelas\n",
    "    TP = cm.diagonal()\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "    accuracy = (TP.sum() + TN.sum()) / (TP.sum() + FP.sum() + FN.sum() + TN.sum())\n",
    "#     accuracy = accuracy_score(test_labels, test_predict)\n",
    "    precision = np.mean(TP / (TP + FP))\n",
    "    sensitivity = np.mean(np.where((TP + FN) == 0, 0, TP / (TP + FN)))\n",
    "    specificity = np.mean(TN / (TN + FP))\n",
    "    f1score = (2 * sensitivity * precision) / (sensitivity + precision)\n",
    "    \n",
    "     # Cetak hasil confusion matrix\n",
    "    for i in range(len(TP)):\n",
    "        print(f'Kelas {i}:')\n",
    "        print(f'TP (True Positive): {TP[i]}')\n",
    "        print(f'FP (False Positive): {FP[i]}')\n",
    "        print(f'FN (False Negative): {FN[i]}')\n",
    "        print(f'TN (True Negative): {TN[i]}')\n",
    "\n",
    "#     Cetak classification report\n",
    "    print(f'Akurasi: {accuracy:.2%}')\n",
    "    print(f'Presisi: {precision:.2%}')\n",
    "    print(f'Sensitivitas: {sensitivity:.2%}')\n",
    "    print(f'F1-score: {f1score:.2%}')\n",
    "\n",
    "    # Simpan evaluasi ke dalam DataFrame\n",
    "    evaluation_dict = {\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Sensitivity': [sensitivity],\n",
    "        'Specificity': [specificity],\n",
    "        'F1-score': [f1score]\n",
    "    }\n",
    "    df_evaluation = pd.DataFrame(evaluation_dict)\n",
    "\n",
    "    return df_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec612b",
   "metadata": {},
   "source": [
    "# 6. Membuat & menyimpan model klasifikasi dengan 100x run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Melakukan 100 running dan menyimpan hasil evaluasi ke dalam DataFrame\n",
    "n_runs = 100\n",
    "evaluation_results = pd.DataFrame()\n",
    "\n",
    "# Inisialisasi list untuk menyimpan scalers dan label encoders\n",
    "scalers = []\n",
    "label_encoders = []\n",
    "\n",
    "for run in range(n_runs):\n",
    "    # Lakukan training dan evaluasi\n",
    "    clf_MLP = MLPClassifier(hidden_layer_sizes=(31, 10), activation='relu', max_iter=1000)\n",
    "    test_labels_MLP, test_predict_MLP = train_classification(clf_MLP, X_train_scaled, y_train_preprocessed, X_test_scaled, y_test_preprocessed)\n",
    "    df_evaluation_MLP = evaluation(clf_MLP, test_labels_MLP, test_predict_MLP, filename=f'MLP{run}')\n",
    "    \n",
    "    # Simpan model\n",
    "    model_filename = f'C:.../.../clf_MLP_{run+1}.joblib' #sesuaikan dengan path\n",
    "    joblib.dump(clf_MLP, model_filename)\n",
    "    print(f\"Model {run+1} saved to {model_filename}\")\n",
    "\n",
    "    # Gabungkan hasil evaluasi ke dalam DataFrame utama\n",
    "    evaluation_results = pd.concat([evaluation_results, df_evaluation_MLP], ignore_index=True)\n",
    "\n",
    "# Menyimpan hasil evaluasi dalam CSV\n",
    "evaluation_results.to_csv('C:.../.../evaluation_results_100_run.csv', index=False) #sesuaikan dengan path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207840c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mencari akurasi tertinggi\n",
    "max_accuracy = evaluation_results['Accuracy'].max()\n",
    "\n",
    "# Mencari akurasi terendah\n",
    "min_accuracy = evaluation_results['Accuracy'].min()\n",
    "\n",
    "# Mencari rata-rata akurasi\n",
    "mean_accuracy = evaluation_results['Accuracy'].mean()\n",
    "\n",
    "# Mencari standar deviasi akurasi\n",
    "std_accuracy = evaluation_results['Accuracy'].std()\n",
    "\n",
    "print(f\"Akurasi Tertinggi: {max_accuracy:.2%}\")\n",
    "print(f\"Akurasi Terendah: {min_accuracy:.2%}\")\n",
    "print(f\"Rata-rata Akurasi: {mean_accuracy:.2%}\")\n",
    "print(f\"Standar Deviasi Akurasi: {std_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce4fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Baca file CSV yang berisi hasil evaluasi\n",
    "df = pd.read_csv('C:.../.../evaluation_results_100_run.csv')\n",
    "\n",
    "# Buat grafik akurasi\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['Accuracy'], marker='o', linestyle='-', label='Akurasi', color='blue')\n",
    "plt.title('Grafik Akurasi MLP dalam 100 kali Run')\n",
    "plt.xlabel('Run ke-')\n",
    "plt.ylabel('Akurasi')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('C:.../.../Grafik Akurasi 100 Kali Run.png')\n",
    "plt.show()\n",
    "\n",
    "# Buat grafik loss curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(clf_MLP.loss_curve_, label='Loss', color='blue')\n",
    "plt.title('Loss Curve untuk Model MLP')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('C:.../.../Grafik Loss.png')\n",
    "plt.show()\n",
    "\n",
    "# Cari akurasi tertinggi, terendah, rata-rata, dan standar deviasi\n",
    "max_accuracy = df['Accuracy'].max()\n",
    "min_accuracy = df['Accuracy'].min()\n",
    "mean_accuracy = df['Accuracy'].mean()\n",
    "std_accuracy = df['Accuracy'].std()\n",
    "\n",
    "# Tampilkan hasil\n",
    "print(f\"Akurasi Tertinggi: {max_accuracy:.2%}\")\n",
    "print(f\"Akurasi Terendah: {min_accuracy:.2%}\")\n",
    "print(f\"Rata-rata Akurasi: {mean_accuracy:.2%}\")\n",
    "print(f\"Standar Deviasi Akurasi: {std_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5fa37b",
   "metadata": {},
   "source": [
    "# 8. Import data testing yang berbeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a713d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv(\"C:.../.../Testing.csv\")\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9194b",
   "metadata": {},
   "source": [
    "# 9. Pengambilan fitur dan class data testing beda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e5e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_new = test.iloc[0:, :-1].values # Features\n",
    "X_test_new = test.iloc[0:, :-1] # Features\n",
    "y_test_new = test.iloc[0:,-1] # Class Target\n",
    "# print(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler()\n",
    "scaler_test = sc.fit(X_test_new)\n",
    "X_new_test_scaled = scaler_test.transform(X_test_new)\n",
    "print(X_new_test_scaled)\n",
    "\n",
    "# LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labels = [\"Anechoic\", \"Heterogeneus\", \"Hipoechoic\"]\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "y_new_test_preprocessed = le.transform(y_test_new)\n",
    "\n",
    "print(y_new_test_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f63d4",
   "metadata": {},
   "source": [
    "# 10. Menggunakan Model yang sudah disimpan untuk data testing yang baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c041ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_filename = 'C:.../.../clf_MLP_61.joblib'\n",
    "clf_MLP_loaded = joblib.load(model_filename)\n",
    "\n",
    "new_data_predictions = clf_MLP_loaded.predict(X_new_test_scaled)\n",
    "\n",
    "evaluation(clf_MLP_loaded, y_new_test_preprocessed, new_data_predictions, filename=\"MLP_New\")\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(clf_MLP_loaded.loss_curve_)\n",
    "plt.title('Loss Curve')\n",
    "plt.xticks(range(0, 701, 50)) \n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.savefig('C:.../.../clf_MLP_61_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca9548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames untuk label sebenarnya dengan hasil klasifikasi\n",
    "actual_labels_df = pd.DataFrame(y_new_test_preprocessed, columns=['Label Sebenarnya'])\n",
    "predicted_labels_df = pd.DataFrame(new_data_predictions, columns=['Hasil Klasifikasi'])\n",
    "\n",
    "# Mengubah label numerik menjadi label sebenarnya\n",
    "label_mapping = {0: 'Anechoic', 1: 'Heterogeneous', 2: 'Hypoechoic'}\n",
    "actual_labels_df['Label Sebenarnya'] = actual_labels_df['Label Sebenarnya'].map(label_mapping)\n",
    "predicted_labels_df['Hasil Klasifikasi'] = predicted_labels_df['Hasil Klasifikasi'].map(label_mapping)\n",
    "\n",
    "results_df = pd.concat([actual_labels_df, predicted_labels_df], axis=1)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
